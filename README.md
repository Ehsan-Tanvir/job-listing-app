# ğŸ’¼ Job Listing App

## Overview

**Job Listing App** is a full-stack web application designed to fetch, manage, and display actuarial job listings from [actuarylist.com](https://www.actuarylist.com). The app includes a web scraper, a Flask backend with PostgreSQL, and a responsive React frontend â€” making it a complete CRUD solution.

This tool is especially helpful for actuaries and job seekers to explore listings with filter and sort options, all in one place.

---

## âœ¨ Features

- **Job Filtering**: Filter Jobs by their Company, Country, Type and Tags.
- **Sorting**: Sort Jobs by posting date (Oldest & Newest).
- **Add Jobs**: User can Add a Job.
- **Edit Jobs**: User can Edit any Job.
- **Delete Jobs**: User can Delete any Job.
- **Scraper**: Pulls fresh job listings using Selenium based on user input.
- **Persistent Storage**: PostgreSQL as Database.
- **Responsive UI**: Clean, Functional, Responsive and Dynamic User Inteface.
- **Reset Filters**: Reset all applied filters with a single click of the "Reset Filters" button..
- **More Job Information**: View detailed information about any job by clicking the "More Info" button on its card.
---

## ğŸ› ï¸ Tech Stack

| Layer    | Technology                       |
| -------- | -------------------------------- |
| Frontend | React (with plain CSS)           |
| Backend  | Flask + SQLAlchemy               |
| Database | PostgreSQL                       |
| Scraper  | Python + Selenium + BeautifulSoup|

---

## ğŸ“ Folder Structure

```
job-listing-app/
â”‚
â”œâ”€â”€ backend/                         # Flask backend
â”‚   â”œâ”€â”€ models/                       # Database models
â”‚   â”‚   â””â”€â”€ job.py                     # Job table model
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                       # API route handlers
â”‚   â”‚   â””â”€â”€ job_routes.py              # Job CRUD routes
â”‚   â”‚
â”‚   â”œâ”€â”€ app.py                        # Flask app entry
â”‚   â”œâ”€â”€ config.py                     # App configuration
â”‚   â”œâ”€â”€ db.py                         # Database setup
â”‚   â””â”€â”€ .env                          # Environment variables
â”‚
â”œâ”€â”€ frontend/                         # React frontend
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/               # UI components
â”‚       â”‚   â”œâ”€â”€ ConfirmDeleteModal.js  # Delete confirm dialog
â”‚       â”‚   â”œâ”€â”€ FilterSortJob.js       # Filter/sort jobs UI
â”‚       â”‚   â”œâ”€â”€ JobCard.js             # Single job display
â”‚       â”‚   â”œâ”€â”€ JobForm.js             # Job form fields
â”‚       â”‚   â”œâ”€â”€ JobFormModal.js        # Job form popup
â”‚       â”‚   â”œâ”€â”€ JobList.js             # List of jobs
â”‚       â”‚   â””â”€â”€ ScrapeModal.js         # Scraper trigger popup
â”‚       â”‚
â”‚       â”œâ”€â”€ api.js                    # API calls helper
â”‚       â”œâ”€â”€ App.js                    # Main React app
â”‚       â”œâ”€â”€ index.css                 # Global styles
â”‚       â””â”€â”€ index.js                  # React entry point
â”‚
â”œâ”€â”€ scraper/                          # Job scraper
â”‚   â””â”€â”€ scrape.py                     # Selenium scraping script
â”‚
â”œâ”€â”€ venv/                             # Python virtual env
â”œâ”€â”€ .gitignore                        # Ignore rules
â”œâ”€â”€ README.md                         # Project documentation
â””â”€â”€ requirements.txt                  # Python dependencies

```

---

## âš™ï¸ Setup & Installation

### Prerequisites

* Python 3.10+
* Node.js (v18+ recommended)
* PostgreSQL (ensure it's running locally [pgadmin])
* Git
* Selenium WebDriver (e.g. ChromeDriver installed and added to PATH)

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Ehsan-Tanvir/job-listing-app.git
cd job-listing-app
```

---

### 2. Setup Python Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

---

### 3. Install Backend Requirements

```bash
pip install -r requirements.txt
```

Make sure PostgreSQL is running and configured correctly in `backend/app.py`:

Create a .env file in the backend/ directory and add the following:

```python
DATABASE_URL = "postgresql://postgres:yourpassword@localhost/joblistings"
```

Then run the backend:

```bash
python3 backend/app.py
```

By default, the backend runs on:
`http://127.0.0.1:5000`

---

### 4. Start Frontend

In another terminal:

```bash
cd frontend
npm install
npm start
```

Frontend runs by default on:
`http://localhost:3000`

---

## ğŸ“Œ Notes

* Just run the app â€” the database table will be created automatically no manual setup required.
* The /scrape POST endpoint runs the integrated scraper with a specified number of pages and automatically stores the scraped job data into the database (no manual file execution required).
---
